
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">

<html>
<head>
<script type="text/javascript">

  function resizeIframe(iframe) {
    var newheight;
    var newwidth;

    if(document.getElementById){
        newwidth=iframe.contentWindow.document.body.scrollWidth;
        newheight=iframe.contentWindow.document.body.scrollHeight;
    }

    iframe.height= (newheight) + "px";
    iframe.width= (newwidth) + "px";
  }
</script>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Submitting High Memory Jobs on CHTC's HTC System</title>

<link href="/web.css" rel="stylesheet" type="text/css">
</head>
<body leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr>
   <td width="1%" align="left" class="bgred" valign="top">
      <div align="center">
      &nbsp;<br>
      <a href="http://www.wisc.edu">

      <img src="/images/uw-sm-red.png" width="125" height="46" border="0"> </a>
       </div>

	<ul class="sidebar">
	<li><a href="/">CHTC Home</a></li>
	
	<li>About
		<ul>
		<li><a href="/approach.shtml">Our Approach</a></li>
<!--comment		<li><a href="/resources.shtml">Our Resources</a></li>   -->
		<li><a href="/projects.shtml">Our Customers</a></li>
		<li><a href="/people.shtml">Our Staff</a></li>
		<li><a href="/jobs.shtml">Our Open Positions</a></li>
		</ul>
	</li>
	
	<li>How To's
		<ul>
		<li><a href="/get-started.shtml">Get Started</a></li>
		<li><a href="/get-help.shtml">Get Help</a></li>
        	<li><a href="/guides.shtml">All User Guides</a></li>
                <li><a href="/use-submit-node.shtml">Use an HTC Submit Server</a></li>
		<li><a href="/helloworld.shtml">Run Your First HTC Jobs</a></li>
		<li><a href="/howto_overview.shtml">HTC for MatLab, Python or R</a></li>
		<li><a href="/hpc-overview.shtml">Use the HPC Cluster</a></li>
		<li><a href="/cite-chtc.shtml">Cite CHTC Resources</a></li>
		</ul>
	</li>
	<li><a href="/user-news.shtml">User News</a></li>
	<li>Other Resources
		<ul>
		<!--<li><a href="http://monitor.chtc.wisc.edu/uw_condor_usage/usage1.shtml">Pool Usage Reports</a></li>-->
<!--comment		<li><a href="/opmetrics.shtml">Operational Metrics</a></li>  -->
		<li><a href="/gpu-lab.shtml">CHTC GPU Lab</a></li>
		<li><a href="http://research.cs.wisc.edu/htcondor/">HTCondor Project</a></li>
		<li><a href="http://www.neos-server.org/">NEOS Optimization Service</a></li>
		<li><a href="http://www.opensciencegrid.org/">Open Science Grid</a></li>
		<li><a href="http://wid.wisc.edu/">WID (Wisconsin Institute for Discovery)</a></li>
		</ul>
	</li>
	</ul>

	</td>

<td width="97%" valign="top"> 


	<TABLE SUMMARY="Navigation layout" BORDER="0" WIDTH="100%" CELLSPACING="0" CELLPADDING="0">
<TR ALIGN="left"> 
  <TD WIDTH="100%" height="400" Align="left" VALIGN="top"> 
    <A  name="body"></a> 
	<div id = "main">

<!-- Top of Page Body -->
<table BORDER="0" WIDTH="100%">
<!-- <h1 align=left valign=center>The Center for High Throughput Computing</h1> -->

<div id="osg_power"> <span style="height: 30px">Powered by:</span><br /><a href="http://opensciencegrid.org"><img alt="Open Science Grid" src="/images/Open_Science_Grid_Consortium(Logo).jpg" width="123" height="70" /></a></div>

<div id="hours"> <span style="height: 30px">
	<a href="https://twitter.com/CHTC_UW" style="color:white;"><center><img alt="Twitter" src="/images/twitter.png" width="50" height="50"></center></a> 
	<center><a href="https://github.com/CHTC/chtc-website-source" style="color:white;"><img alt="GitHub" src="/images/GitHub_Logo_White.png" width="92" height="38"></center></a></span></div>

<div id="hours"> <span style="height: 35px">
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<a href="http://chtc.cs.wisc.edu/get-help.shtml" style="color:white;">
<center><b>Office Hours!</b>
<p style="margin-bottom: 1px;"></p>
Tues/Thurs, 3-5pm
Click for details
</center></a></span>
<p style="margin-bottom: 1px;"></p>
<center><a href="http://chtc.cs.wisc.edu/sign-in.shtml" style="color:white;">Sign-In Here</a></center>
</div>
	
<div style="margin-top:1em;"><a href="http://chtc.cs.wisc.edu/"><img alt="Center for High Throughput Computing" src="/images/CHTC-logo.png" width="500" height="90"></a></div>

<h1>Submitting High Memory Jobs on CHTC's HTC System</h1>


<p><strong>The examples and information in the below guide areuseful ONLY if:</strong></p>
<ul>
  <li>you already have an account on a CHTC-administered submit server</li>
  <li>your jobs will use more than ~120 GB of memory</li>
</ul>

<p><strong>To best understand the below information, users should already befamiliar with:</strong></p>
<ol>
  <li>Using the command-line to: navigate directories,
create/edit/copy/move/delete files and directories, and run intended
programs (aka "executables").</li>
  <li><a href="/helloworld.shtml">CHTC's Intro to Running HTCondor Jobs</a></li>
  <li>CHTC's guides for handling large data (<a href="/file-avail-largedata.shtml">Guide
here</a>) and software installation.</li>
</ol>

<h2 id="overview">Overview</h2>

<p>A high-memory job is one that requires a significantly larger amount of
memory (also known as RAM) than a typical high throughput job usually
over 200 GB and up to 1-4 TB. In the following guide, we cover resources
and recommendations for running high-memory work in CHTC. <strong>However,
please make sure to email us if you believe you will need to run
"high-memory" work for the first time, or are planning the execution
of new "high-memory" work that is different from what you've run
before.</strong> We'll happily help you with some personalized tips and
considerations for getting your work done most efficiently.</p>

<ol>
  <li><a href="#resources">High Memory Resources in CHTC</a></li>
  <li><a href="#get-started">Getting Started</a></li>
  <li><a href="#running">Running High Memory Jobs</a></li>
</ol>

<p><a name="resoures"></a></p>

<h1 id="1-high-memory-resources-in-chtc"><strong>1. High Memory Resources in CHTC</strong></h1>

<p>Our high memory servers have the following specs:</p>

<table class="gtable">
  <thead>
    <tr>
      <th>Number of servers</th>
      <th>Memory per server</th>
      <th>CPUs per server</th>
      <th>Local disk space on server</th>
      <th>Names</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>512 GB</td>
      <td>16</td>
      <td>2.5 TB</td>
      <td><code>wid-003</code></td>
    </tr>
    <tr>
      <td>16</td>
      <td>512 GB</td>
      <td>40</td>
      <td>1.2 TB</td>
      <td><code>e2003</code>-<code>e2018</code></td>
    </tr>
    <tr>
      <td>2</td>
      <td>2 TB</td>
      <td>80</td>
      <td>3.5+ TB</td>
      <td><code>mem2001</code>, <code>mem2002</code></td>
    </tr>
    <tr>
      <td>1</td>
      <td>4 TB</td>
      <td>80</td>
      <td>6 TB</td>
      <td><code>mem3</code></td>
    </tr>
  </tbody>
</table>

<p><a name="get-started"></a></p>

<h1 id="2-getting-started"><strong>2. Getting Started</strong></h1>

<p><a name="id"></a></p>

<h2 id="a-identifying-high-memory-jobs">A. Identifying High Memory Jobs</h2>

<p>Jobs that request over 200GB of memory in their <a href="#submit">submit file</a>
can run on our dedicated high memory machines. However, if your job
doesn't need quite that much memory, it's good to request less, as
doing so will allow your job(s) to run on more servers, since CHTC has
hundreds of servers with up to 100 GB of memory and dozens of servers
with up to 250 GB of memory.</p>

<p><a name="testing"></a></p>

<h2 id="b-testing">B. Testing</h2>

<p>Before running a full-size high-memory job, make sure to use a small
subset of data in a test job. Not only will this give you a chance to
try out the submit file syntax and make sure your job runs, but it can
help you estimate how much memory and/or disk you will need for a job
using your full data.</p>

<p>You can also use interactive jobs to test commands that will end up in
your "executable" script. To run an interactive job, prepare your
submit file as usual. Note that for an interactive job, you should use a
smaller memory request (and possibly lower CPU and disk as well) than
for the final job (so that the interactive job starts) and plan to
simply test commands, not run the entire program. To submit interactive
job, use the <code>-i</code> flag with <code>condor_submit</code>:</p>

<pre class="term"><code>[alice@submit]$ condor_submit -i submit.file
</code></pre>

<p>After waiting for the interactive job to start, this should open a bash
session on an execute machine, which will allow you to test your
commands interactively. Once your testing is done, make the appropriate
changes to your executable, adjust your resource requests, and submit
the job normally.</p>

<p><a name="consult"></a></p>

<h2 id="c-consult-with-facilitators">C. Consult with Facilitators</h2>

<p>If you are unsure how to run high-memory jobs on CHTC, or if you're not
sure if everything in this guide applies to you, get in touch with a
research computing facilitator by emailing <a href="chtc@cs.wisc.edu">chtc@cs.wisc.edu</a>.</p>

<p><a name="running"></a></p>

<h1 id="3-running-high-memory-job"><strong>3. Running High Memory Job</strong></h1>

<p><a name="submit"></a></p>

<h2 id="a-submit-file">A. Submit File</h2>

<p>The submit file shown in our <a href="/helloworld.shtml">Hello World example</a> is
a good starting point for building your high memory job submit file. The
following are places where it's important to customize:</p>

<ul>
  <li>
    <p><strong><code>request_memory</code></strong>: It is crucial to make this request as accurate
as you can by <a href="#testing">testing</a> at a small scale if possible (see
above). Online documentation/help pages or your colleagues'
experience is another source of information about required memory.</p>
  </li>
  <li><strong>Long running jobs</strong>: If your high memory job is likely to run
longer than our 3-day time limit, please email us for options on how
to run for longer. In the past, high memory jobs received an extra
time allowance automatically but this is no longer the case.</li>
  <li>
    <p><strong><code>request_cpus</code></strong>: Sometimes, programs that use a large amount of
memory can also take advantage of multiple CPUs. If this is the case
for your program, you can request multiple CPUs. However, <strong>it is
always easier to start jobs that request fewer number of cores,
rather than more</strong>. We recommend:</p>

    <table class="gtable">
      <thead>
        <tr>
          <th>Requesting ___ of memory?</th>
          <th>Request fewer than ___ CPUs</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>up to 100 GB</td>
          <td>4</td>
        </tr>
        <tr>
          <td>100-500 GB</td>
          <td>8</td>
        </tr>
        <tr>
          <td>500GB-1TB</td>
          <td>16</td>
        </tr>
        <tr>
          <td>1-1.5TB</td>
          <td>20</td>
        </tr>
        <tr>
          <td>1.5-2TB</td>
          <td>20</td>
        </tr>
        <tr>
          <td>2TB or greater</td>
          <td>32</td>
        </tr>
      </tbody>
    </table>

    <p>If you think a higher CPU request would significantly improve your
job's performance, contact a facilitator.</p>
  </li>
  <li>
    <p><strong><code>request_disk</code></strong>: Request the maximum amount of data your job will
ever have within the job working directory on the execute node,
including all output and input (which will take up space before some
of it is removed from the job working directory at the end of the
job).</p>
  </li>
  <li><strong>Other requirements</strong>: if your job uses files from <a href="/file-avail-largedata.shtml">our large data
space</a>, or <a href="/docker-jobs.shtml">Docker for
software</a>, add the necessary requirements for
these resources to your submit file.</li>
</ul>

<p>Altogether, a sample submit file may look something like this:</p>

<pre><code class="language-{.sub}">### Example submit file for a single staging-dependent job

universe = vanilla

# Files for the below lines will all be somewhere within /home/username,
# and not within /staging/username
log = run_myprogram.log
executable = run_Trinity.sh
output = $(Cluster).out
error = $(Cluster).err
transfer_input_files = trinityrnaseq-2.0.1.tar.gz
should_transfer_files = YES

# Require execute servers that have large data staging
Requirements = (Target.HasCHTCStaging == true)

# Memory, disk and CPU requests
request_memory = 200GB
request_disk = 100GB
request_cpus = 4

# Submit 1 job
queue 1
### END
</code></pre>

<p><a name="software"></a></p>

<h2 id="b-software">B. Software</h2>

<p>Like any other job, the best option for high memory work is to create a
portable installation of your software. We have guides for <a href="/howto_overview.shtml">scripting
languages</a> and <a href="/docker-jobs.shtml">using
Docker</a>, and can otherwise provide individual
support for program installation <a href="/get-help.shtml">during office hours or over
email</a>.</p>

<p><a name="executable"></a></p>

<h2 id="c-executable-script">C. "Executable" script</h2>

<p>As described in many of our guides (for
<a href="/howto_overview.shtml">software</a> or for using <a href="/file-avail-largedata.shtml">large
data</a>), you will need to write a script
that will run your software commands for you and that will serve as the
submit file "executable". Things to note are:</p>

<ul>
  <li>If using files from our large data staging space, follow the
recommendations in our <a href="/file-avail-largedata.shtml">guide</a>.</li>
  <li>If using multiple cores, make sure that you request the same number
of "threads" or "processes" in your command as you requested in
your <a href="#submit">submit file</a>.</li>
</ul>

<p>Altogether, a sample script may look something like this (perhaps called
<code>run_Trinity.sh</code>):</p>

<pre class="file"><code>#!/bin/bash
# Copy input data from /staging to the present directory of the job
# and un-tar/un-zip them.  
cp /staging/username/reads.tar.gz ./
tar -xzvf reads.tar.gz
rm reads.tar.gz

# Set up the software installation in the job working directory, and 
# add it to the job's PATH
tar -xzvf trinityrnaseq-2.0.6-installed.tar.gz
rm trinityrnaseq-2.0.6-installed.tar.gz
export PATH=$(pwd)/trinityrnaseq-2.0.6:$PATH

# Run software command, referencing input files in the working directory and 
# redirecting "stdout" to a file.  Backslashes are line continuation.
Trinity --seqType fq --left reads_1.fq \
--right reads_2.fq --CPU 4 --max_memory \
20G &gt; trinity_stdout.txt

# Trinity will write output to the working directory by default, 
# so when the job finishes, it needs to be moved back to /staging
tar -czvf trinity_out_dir.tar.gz trinity_out_dir
cp trinity_out_dir.tar.gz trinity_stdout.txt /staging/username/
rm reads_*.fq trinity_out_dir.tar.gz trinity_stdout.txt

### END
</code></pre>



<div id = "copyright">
     <p align = "center"> 
	  
     For all user support, questions, and comments:
     <strong><a href="mailto:chtc@cs.wisc.edu">chtc@cs.wisc.edu</a></strong>

</p>
</div>

</div>

  </td>
  </tr>

</TABLE>
</td>
</table>

</body>
</html>


