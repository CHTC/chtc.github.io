
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">

<html>
<head>
<script type="text/javascript">

  function resizeIframe(iframe) {
    var newheight;
    var newwidth;

    if(document.getElementById){
        newwidth=iframe.contentWindow.document.body.scrollWidth;
        newheight=iframe.contentWindow.document.body.scrollHeight;
    }

    iframe.height= (newheight) + "px";
    iframe.width= (newwidth) + "px";
  }
</script>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Managing Large Data in HTC Jobs with S3 Buckets</title>

<link href="/web.css" rel="stylesheet" type="text/css">
</head>
<body leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr>
   <td width="1%" align="left" class="bgred" valign="top">
      <div align="center">
      &nbsp;<br>
      <a href="http://www.wisc.edu">

      <img src="/images/uw-sm-red.png" width="125" height="46" border="0"> </a>
       </div>

	<ul class="sidebar">
	<li><a href="/">CHTC Home</a></li>
	
	<li>About
		<ul>
		<li><a href="/approach.shtml">Our Approach</a></li>
<!--comment		<li><a href="/resources.shtml">Our Resources</a></li>   -->
		<li><a href="/projects.shtml">Our Customers</a></li>
		<li><a href="/people.shtml">Our Staff</a></li>
		<li><a href="/jobs.shtml">Our Open Positions</a></li>
		</ul>
	</li>
	
	<li>How To's
		<ul>
		<li><a href="/get-started.shtml">Get Started</a></li>
		<li><a href="/get-help.shtml">Get Help</a></li>
        	<li><a href="/guides.shtml">All User Guides</a></li>
                <li><a href="/use-submit-node.shtml">Use an HTC Submit Server</a></li>
		<li><a href="/helloworld.shtml">Run Your First HTC Jobs</a></li>
		<li><a href="/howto_overview.shtml">HTC for MatLab, Python or R</a></li>
		<li><a href="/HPCuseguide.shtml">Use the HPC Cluster</a></li>
		<li><a href="/cite-chtc.shtml">Cite CHTC Resources</a></li>
		</ul>
	</li>
	<li><a href="/user-news.shtml">User News</a></li>
	<li>Other Resources
		<ul>
		<!--<li><a href="http://monitor.chtc.wisc.edu/uw_condor_usage/usage1.shtml">Pool Usage Reports</a></li>-->
<!--comment		<li><a href="/opmetrics.shtml">Operational Metrics</a></li>  -->
		<li><a href="/gpu-lab.shtml">CHTC GPU Lab</a></li>
		<li><a href="http://research.cs.wisc.edu/htcondor/">HTCondor Project</a></li>
		<li><a href="http://www.neos-server.org/">NEOS Optimization Service</a></li>
		<li><a href="http://www.opensciencegrid.org/">Open Science Grid</a></li>
		<li><a href="http://wid.wisc.edu/">WID (Wisconsin Institute for Discovery)</a></li>
		</ul>
	</li>
	</ul>

	</td>

<td width="97%" valign="top"> 


	<TABLE SUMMARY="Navigation layout" BORDER="0" WIDTH="100%" CELLSPACING="0" CELLPADDING="0">
<TR ALIGN="left"> 
  <TD WIDTH="100%" height="400" Align="left" VALIGN="top"> 
    <A  name="body"></a> 
	<div id = "main">

<!-- Top of Page Body -->
<table BORDER="0" WIDTH="100%">
<!-- <h1 align=left valign=center>The Center for High Throughput Computing</h1> -->

<div id="osg_power"> <span style="height: 30px">Powered by:</span><br /><a href="http://opensciencegrid.org"><img alt="Open Science Grid" src="/images/Open_Science_Grid_Consortium(Logo).jpg" width="123" height="70" /></a></div>

<div id="hours"> <span style="height: 30px">
	<a href="https://twitter.com/CHTC_UW" style="color:white;"><center><img alt="Twitter" src="/images/twitter.png" width="50" height="50"></center></a> 
	<center><a href="https://github.com/CHTC/chtc-website-source" style="color:white;"><img alt="GitHub" src="/images/GitHub_Logo_White.png" width="92" height="38"></center></a></span></div>

<div id="hours"> <span style="height: 35px">
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<a href="http://chtc.cs.wisc.edu/get-help.shtml" style="color:white;">
<center><b>Office Hours!</b>
<p style="margin-bottom: 1px;"></p>
Tues/Thurs, 3-5pm
Click for details
</center></a></span>
<p style="margin-bottom: 1px;"></p>
<center><a href="http://chtc.cs.wisc.edu/sign-in.shtml" style="color:white;">Sign-In Here</a></center>
</div>
	
<div style="margin-top:1em;"><a href="http://chtc.cs.wisc.edu/"><img alt="Center for High Throughput Computing" src="/images/CHTC-logo.png" width="500" height="90"></a></div>

<h1>Managing Large Data in HTC Jobs with S3 Buckets</h1>

<h2>Which Option is the Best for Your Files?</h2>
<br>
<table class="gtable">
<tr>
	<th> </th>	
	<th>Meant For</th>	
	<th>Input/Software File Sizes</th>
	<th>Output File Sizes</th>
	<th>Available for Jobs Running ...</th>
	<th>File Security</th>
	<th>Special Considerations</th>
</tr>

<tr>
	<td><a href="file-availability.shtml">HTCondor File Transfer</a></td>		
	<td>basic file delivery and return; see size limits at right</td>
	<td>0 - 100 MB per file; <500 MB total per job</td>
	<td>0 - 4 GB total	</td>
	<td>in CHTC, UW Grid, and OSG</td>
	<td>available to <i>your</i> jobs, on CHTC and beyond</td>
	<td><font color="red">DO NOT USE for files in <code>/staging</code> OR <code>/squid</code></font></td>
</tr>

<tr>
	<td><a href="file-avail-squid.shtml">SQUID Web Proxy</a></td>
	<td>large input or software shared by <i>many</i> jobs</td>
	<td>100 MB - 1 GB per shared file</td>
	<td>N/A</td>
	<td>in CHTC, UW Grid, and OSG</td>
	<td>files will be world-<i>readable</i></td>
	<td>large files unique to individual jobs are better for large data staging</td>
</tr>

<tr>
	<td><a href="file-avail-largedata.shtml">Large Data Staging</a></td>
	<td>largest software, input, and output</td>
	<td>100 MB - TBs per unique file; 1GB - TBs per shared file</td>
	<td>4 GB - TBs</td>
	<td>in only a portion of CHTC</td>
	<td>accessible ONLY to your jobs on specific CHTC servers</td>
	<td>special submit "Requirements"</td>
</tr>
</table>

<!--
<h2>Best Practices for File Delivery</h2>

<p>Remember to review best practices in our File Handling guide, 
including the following:</p>

<ul>
<li>Pre-split large input files when each of many jobs will only need a portion of the 
large input data.</li>
<li>Remove ALL unwanted/temporary files in the working director of the job that have 
appeared since the job started.</li>
<li>Use tar with compression (*.tar.gz) for any relevant input/output files and ALL 
desired output directories prior to their transfer/delivery.</li>
</ul>
-->


<p>When submitting jobs to CHTC’s High Throughput Computing (HTC) system,
there is a distinct location for staging data that is too large to be
handled at scale via the default HTCondor file transfer mechanism
but needs to be accessed outside of CHTC
(for example, data for jobs that run on the Open Science Grid).</p>

<p><strong>To best understand the below information, users should already be
familiar with:</strong></p>

<ol>
  <li>Using the command-line to: navigate directories,
create/edit/copy/move/delete files and directories, and run intended
programs (aka “executables”).</li>
  <li>CHTC’s <a href="/helloworld.shtml">Intro to Running HTCondor Jobs</a></li>
  <li>CHTC’s guide for <a href="/file-availability.shtml">Typical File Transfer</a></li>
</ol>

<h2 id="contents">Contents</h2>

<ol>
  <li><a href="#1-policies-and-intended-use">Policies and Intended Use</a></li>
  <li><a href="#2-staging-large-data-in-s3-buckets">Staging Large Data in S3 Buckets</a></li>
  <li><a href="#3-using-staged-files-in-a-job">Using Staged Files in a Job</a>
    <ul>
      <li><a href="#a-transferring-large-input-files">Transferring Large Input Files</a></li>
      <li><a href="#b-moving-large-output-files">Moving Large Output Files</a></li>
    </ul>
  </li>
  <li><a href="#4-checking-your-data-use-and-object-counts">Checking your Data Use and File Counts</a></li>
</ol>

<h1 id="1-policies-and-intended-use">1. Policies and Intended Use</h1>

<blockquote>
  <p><strong>USERS VIOLATING ANY OF THE POLICIES IN THIS GUIDE WILL
HAVE THEIR DATA STAGING ACCESS AND/OR CHTC ACCOUNT REVOKED UNTIL CORRECTIVE
MEASURES ARE TAKEN. CHTC STAFF RESERVE THE RIGHT TO REMOVE ANY
PROBLEMATIC USER DATA AT ANY TIME IN ORDER TO PRESERVE PERFORMANCE.</strong></p>
</blockquote>

<h2 id="a-intended-use">A. Intended Use</h2>

<p>Our S3 data storage is only for input and output files that
are individually too large to be managed by our other data movement
methods, HTCondor file transfer or SQUID, and when these files are
expected to be accessed outside of CHTC. This includes individual input files
greater than 100MB and individual output files greater than 3-4GB.</p>

<p>Files in our S3 data storage are organized in storage units called
“buckets.” You can think of an S3 bucket like a folder containing a
set of data. Each bucket has a unique name of your choosing and can
contain folders, executable files, data files, and most other types of
files. S3 buckets are protected with a key that is unique to you
(similar to a password) and, when provided with the key, buckets
can be accessed from any machine with an internet connection. CHTC
automatically creates and manages keys for users, so you do not have
to provide your key when manging files in your S3 buckets on CHTC
transfer servers or when submitting jobs on CHTC submit servers that
transfer data from S3 buckets.</p>

<p>Users are expected to abide by this intended use expectation and follow the
instructions for using S3 buckets written in this guide (e.g. files placed
in S3 buckets should ALWAYS be listed in the submit file).</p>

<h2 id="b-getting-access-to-create-s3-buckets">B. Getting Access to Create S3 Buckets</h2>

<p>Any one with a CHTC account whose data meets the intended use above
can request access to create S3 buckets inside CHTC’s S3 data
storage. A Research Computing Facilitator will review the request and
follow up. If appropriate, S3 bucket creation will be enabled for and
a quota will be set on your account. Quotas are based on individual
user needs; if a larger quota is needed, email chtc@cs.wisc.edu with
your request.</p>

<h2 id="c-user-data-management-responsibilities">C. User Data Management Responsibilities</h2>

<p>As with all CHTC file spaces:</p>

<ul>
  <li><strong>Keep copies</strong>: Our S3 buckets are not backed up and have the
possibility of data loss; keep copies of ANY and ALL data in S3
buckets in another, non-CHTC location.</li>
  <li><strong>Remove data</strong>: We expect that users remove data from S3 buckets AS
SOON AS IT IS NO LONGER NEEDED FOR ACTIVELY-RUNNING JOBS.</li>
  <li><strong>Monitor usage and quota</strong>: Your account has both a size and
number of files quota that applies across all buckets owned by your
account. Quota changes can be requested by emailing chtc@cs.wisc.edu.</li>
</ul>

<p>CHTC staff reserve the right to remove S3 buckets or revoke bucket
creation permission at any time.</p>

<h2 id="d-data-access-within-jobs">D. Data Access Within Jobs</h2>

<p>Data in a CHTC S3 bucket can be accessed from jobs running almost
anywhere (including most of OSG). HTCondor automatically matches and
runs jobs that use S3 buckets only on machines that support S3 data
transfers.</p>

<p>Data in CHTC S3 buckets are owned by the user (or a set of users), and
only the user’s (or users’) own jobs can access these files.</p>

<h1 id="2-staging-large-data-in-s3-buckets">2. Staging Large Data in S3 Buckets</h1>

<p>In order to stage data in an S3 bucket for use on CHTC’s HTC system:</p>

<ul>
  <li><strong>Get S3 bucket creation access</strong>: Bucket creation access is granted by request.</li>
  <li><strong>Create an S3 bucket</strong>: Create a bucket that will contain the data for your project.</li>
  <li><strong>Reduce file counts</strong>: Combine and compress files that are used together.</li>
  <li><strong>Use the transfer server</strong>: Upload your data to your bucket via our dedicated file transfer server.</li>
  <li><strong>Remove files after jobs complete</strong>: Data in S3 buckets are quota controlled and not backed up.</li>
</ul>

<h2 id="a-get-s3-bucket-creation-access">A. Get S3 Bucket Creation Access</h2>

<p>CHTC S3 bucket creation access is granted by request. If you think you need
to create S3 buckets, email CHTC’s Research Computing Facilitators (chtc@cs.wisc.edu).</p>

<h2 id="b-create-an-s3-bucket">B. Create an S3 Bucket</h2>

<p>Buckets can be created on a CHTC submit server or the CHTC transfer server
using the <code>mc</code> command:</p>

<pre class="term"><code>[alice@transfer]$ mc mb chtc/my-bucket-name
</code></pre>

<p>Each bucket in CHTC must have a unique name, so be descriptive! We
recommend creating a bucket per dataset or per batch of jobs.</p>

<h2 id="c-reduce-file-counts">C. Reduce File Counts</h2>

<p>Data placed in S3 buckets should be stored in as few files as possible
(ideally, one file per job). Similarly, large output should first be
written to the job working directory then compressed in to a single
file before being transferred back to an S3 bucket at the end of the job.</p>

<p>To prepare job-specific data that is large enough
and exists as multiple files or directories (or a directory of multiple
files), first create a compressed tar package before placing the file in
an S3 bucket (either before submitting jobs, or within jobs before
transferring output to). For example:</p>

<pre class="term"><code>$ tar -czvf job_package.tar.gz file_or_dir
</code></pre>

<h2 id="d-use-the-transfer-server">D. Use the Transfer Server</h2>

<p>Movement of large data into/out of S3 buckets before and after jobs
should be performed via CHTC’s transfer server, as below, and
<strong>not via a CHTC submit server.</strong> After obtaining an account on the
transfer server and creating an S3 bucket, copy relevant files directly into your
home directory from your own computer:</p>

<ul>
  <li>Example <code>scp</code> command on your own Linux or Mac computer:
    <pre class="term"><code>$ scp large-input.file username@transfer.chtc.wisc.edu:/home/username/
</code></pre>
  </li>
  <li>If using a Windows computer:
    <ul>
      <li>Using a file transfer application, like WinSCP, directly drag the large
file from its location on your computer to a location within
<code>/home/username/</code> on transfer.chtc.wisc.edu.</li>
    </ul>
  </li>
</ul>

<p>Then in an SSH session on the transfer server, copy files in to your
S3 bucket:</p>

<pre class="term"><code>[alice@transfer]$ mc cp large-input.file chtc/my-bucket
</code></pre>

<h2 id="e-remove-files-after-jobs-complete">E. Remove Files After Jobs Complete</h2>

<p>As with all CHTC file spaces, data should be removed from S3 buckets AS
SOON AS IT IS NO LONGER NEEDED FOR ACTIVELY-RUNNING JOBS. Even if it
will be used again in the future, it should be deleted from and copied
back at a later date. Files can be taken out of S3 buckets using similar
mechanisms as uploaded files. In an SSH session on the transfer
server, copy files from your bucket to your home directory:</p>

<pre class="term"><code>[alice@transfer]$ mc cp chtc/my-bucket/large-output.file .
</code></pre>

<p>Then copy files from the transfer server to your own computer:</p>

<ul>
  <li>Example <code>scp</code> command on your own Linux or Mac computer:
    <pre class="term"><code>$ scp username@transfer.chtc.wisc.edu:/home/username/large-output.file .
</code></pre>
  </li>
  <li>If using a Windows computer:
    <ul>
      <li>Using a file transfer application, like WinSCP, directly drag the large
file from its location within <code>/home/username/</code> on
transfer.chtc.wisc.edu to your computer.</li>
    </ul>
  </li>
</ul>

<p>To remove a file inside your S3 bucket, in an SSH session on the
transfer server:</p>

<pre class="term"><code>[alice@transfer]$ mc rm chtc/my-bucket/large-input.file
[alice@transfer]$ mc rm chtc/my-bucket/large-output.file
</code></pre>

<p>To remove an entire bucket (<strong>only do this if you are certain the
bucket is no longer needed</strong>):</p>

<pre class="term"><code>[alice@transfer]$ mc rb chtc/my-bucket
</code></pre>

<h1 id="3-using-staged-files-in-a-job">3. Using Staged Files in a Job</h1>

<h2 id="a-transferring-large-input-files">A. Transferring Large Input Files</h2>

<p>To use data placed in a CHTC S3 bucket, add files to your submit
file’s <code>transfer_input_files</code> that point to the filename
(e.g. <code>large-input.file</code>) inside your bucket (e.g. <code>my-bucket</code>) on
CHTC’s S3 storage (<code>s3dev.chtc.wisc.edu</code>):</p>

<pre class="sub"><code>...
executable = my_script.sh
transfer_input_files = s3://s3dev.chtc.wisc.edu/my-bucket/large-input.file
arguments = large-input.file
...
</code></pre>

<h2 id="b-moving-large-output-files">B. Moving Large Output Files</h2>

<p>To have your job automatically copy data back to your CHTC S3 bucket,
add file mappings to a <code>transfer_output_remaps</code> command inside your
submit file:</p>

<pre class="sub"><code>transfer_output_remaps = "large-output.file = s3://s3dev.chtc.wisc.edu/my-bucket/large-output.file"
</code></pre>

<h1 id="4-checking-your-data-use-and-file-counts">4. Checking Your Data Use and File Counts</h1>

<p>To check what files are in your bucket and the size of the files:</p>
<pre class="term"><code>[alice@submit]$ mc ls chtc/my-bucket
</code></pre>

<p>To check your bucket’s total data usage:</p>
<pre class="term"><code>[alice@submit]$ mc du chtc/my-bucket
</code></pre>

<p>To check your bucket’s file count:</p>
<pre class="term"><code>[alice@submit]$ mc find chtc/my-bucket | wc -l
</code></pre>



<div id = "copyright">
     <p align = "center"> 
	  
     For all user support, questions, and comments:
     <strong><a href="mailto:chtc@cs.wisc.edu">chtc@cs.wisc.edu</a></strong>

</p>
</div>

</div>

  </td>
  </tr>

</TABLE>
</td>
</table>

</body>
</html>


