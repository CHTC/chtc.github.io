
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">

<html>
<head>
<script type="text/javascript">

  function resizeIframe(iframe) {
    var newheight;
    var newwidth;

    if(document.getElementById){
        newwidth=iframe.contentWindow.document.body.scrollWidth;
        newheight=iframe.contentWindow.document.body.scrollHeight;
    }

    iframe.height= (newheight) + "px";
    iframe.width= (newwidth) + "px";
  }
</script>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Jobs That Use GPUs</title>

<link href="/web.css" rel="stylesheet" type="text/css">
</head>
<body leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr>
   <td width="1%" align="left" class="bgred" valign="top">
      <div align="center">
      &nbsp;<br>
      <a href="http://www.wisc.edu">

      <img src="/images/uw-sm-red.png" width="125" height="46" border="0"> </a>
       </div>

	<ul class="sidebar">
	<li><a href="/">CHTC Home</a></li>
	
	<li>About
		<ul>
		<li><a href="/approach.shtml">Our Approach</a></li>
<!--comment		<li><a href="/resources.shtml">Our Resources</a></li>   -->
		<li><a href="/projects.shtml">Our Customers</a></li>
		<li><a href="/people.shtml">Our Staff</a></li>
		<li><a href="/jobs.shtml">Our Open Positions</a></li>
		</ul>
	</li>
	
	<li>How To's
		<ul>
		<li><a href="/get-started.shtml">Get Started</a></li>
		<li><a href="/get-help.shtml">Get Help</a></li>
        	<li><a href="/guides.shtml">All User Guides</a></li>
                <li><a href="/use-submit-node.shtml">Use an HTC Submit Server</a></li>
		<li><a href="/helloworld.shtml">Run Your First HTC Jobs</a></li>
		<li><a href="/howto_overview.shtml">HTC for MatLab, Python or R</a></li>
		<li><a href="/HPCuseguide.shtml">Use the HPC Cluster</a></li>
		<li><a href="/cite-chtc.shtml">Cite CHTC Resources</a></li>
		</ul>
	</li>
	<li><a href="/user-news.shtml">User News</a></li>
	<li>Other Resources
		<ul>
		<!--<li><a href="http://monitor.chtc.wisc.edu/uw_condor_usage/usage1.shtml">Pool Usage Reports</a></li>-->
<!--comment		<li><a href="/opmetrics.shtml">Operational Metrics</a></li>  -->
		<li><a href="/gpu-lab.shtml">CHTC GPU Lab</a></li>
		<li><a href="http://research.cs.wisc.edu/htcondor/">HTCondor Project</a></li>
		<li><a href="http://www.neos-server.org/">NEOS Optimization Service</a></li>
		<li><a href="http://www.opensciencegrid.org/">Open Science Grid</a></li>
		<li><a href="http://wid.wisc.edu/">WID (Wisconsin Institute for Discovery)</a></li>
		</ul>
	</li>
	</ul>

	</td>

<td width="97%" valign="top"> 


	<TABLE SUMMARY="Navigation layout" BORDER="0" WIDTH="100%" CELLSPACING="0" CELLPADDING="0">
<TR ALIGN="left"> 
  <TD WIDTH="100%" height="400" Align="left" VALIGN="top"> 
    <A  name="body"></a> 
	<div id = "main">

<!-- Top of Page Body -->
<table BORDER="0" WIDTH="100%">
<!-- <h1 align=left valign=center>The Center for High Throughput Computing</h1> -->

	

<div id="osg_power"> <span style="height: 20px">Powered by:</span><br /><a href="http://opensciencegrid.org"><img alt="Open Science Grid" src="/images/Open_Science_Grid_Consortium(Logo).jpg" width="123" height="70" /></a></div>

	

<div id="hours"> <span style="height: 20px">
	<center><b>Follow us on social media:</b><a href="https://twitter.com/CHTC_UW"><img alt="Twitter" src="/images/twitter.png" width="70" height="70"></center></a></span></div>
	
	
<div id="hours"> <span style="height: 40px">
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<a href="http://chtc.cs.wisc.edu/get-help.shtml" style="color:white;">
<b>Office Hours!</b>
<br>
Tues/Thurs, 3-4:30pm<br>
Click for details</a>
<p style="margin-bottom: 1px;"></p>
<a href="http://chtc.cs.wisc.edu/sign-in.shtml" style="color:white;">Sign-In Here</a>
</a></span></div>	


	


<div style="margin-top:1em;"><a href="http://chtc.cs.wisc.edu/"><img alt="Center for High Throughput Computing" src="/images/CHTC-logo.png" width="500" height="90"></a></div>

<h1>Jobs That Use GPUs</h1>


<h1 id="overview">Overview</h1>

<p>GPUs (Graphical Processing Units) are a special kind of computer
processor that are optimized for running very large numbers of simple
calculations in parallel, which often can be applied to problems related
to image processing or machine learning. Well-crafted GPU programs for
suitable applications can outperform implementations running on CPUs by
a factor of ten or more, <em>but only when the program is written and
designed explicitly to run on GPUs using special libraries like CUDA</em>.
For researchers who have problems that are well-suited to GPU
processing, it is possible to run jobs that use GPUs in CHTC. Read on to
determine:</p>

<ol>
  <li><a href="#1-gpus-available-in-chtc">GPUs available in CHTC</a></li>
  <li><a href="#2-submit-jobs-using-gpus">Submit Jobs Using GPUs</a></li>
  <li><a href="#3-preparing-software-using-gpus">Preparing Software Using GPUs</a></li>
  <li><a href="#4-using-gpus-on-the-open-science-grid">Using GPUs on the Open Science Grid</a></li>
</ol>

<blockquote>
  <p>This is the initial version of a guide about running GPU jobs in CHTC.
If you have any suggestions for improvement, or any questions about
using GPUs in CHTC, please email the research computing facilitators
at chtc@cs.wisc.edu.</p>
</blockquote>

<h1 id="1-gpus-available-in-chtc">1. GPUs Available in CHTC</h1>

<p>CHTC’s high throughput (HTC) system has the following servers with GPU
capabilities (as of 3/16/2020):</p>

<h2 id="a-general-use-gpus-via-the-chtc-gpu-lab">A. General Use GPUs via the CHTC GPU Lab</h2>

<p>There are a limited number of shared use GPUs available through the CHTC GPU
Lab. Therefore, these servers have different policies about job runtimes and
the maximum number of running jobs per user than general CHTC servers.
These GPUs are a special investment from the UW2020 program, and the policies
aim to maximize how many researchers can benefit from this investment.</p>

<p>By opting-in to use the CHTC GPU Lab servers, you agree to be contacted by the
project leaders occasionally to discuss your GPU computing and help improve the
GPU Lab.</p>

<table class="gtable">
  <tr>
    <th>Number of Servers</th>
    <th>Names</th>
    <th>GPUs / Server</th>
    <th>GPU Type</th>
    <th>Current OS</th>
    <th>HasCHTCStaging</th>
  </tr>
<!--  <tr>
    <td>gpu-3.chtc.wisc.edu</td> 
    <td>1 </td>
    <td>Tesla K40c</td>
  </tr>   -->  
  <tr>
    <td>2</td>
    <td>gpu2000, gpu2001</td>
    <td>2</td>
    <td>Tesla P100-PCIE-16GB</td>
    <td>CentOS 7</td>
    <td>yes</td>
  </tr>
  <tr>
    <td>4</td>
    <td>gpu2002 - gpu2005</td>
    <td>8</td>
    <td>GeForce RTX 2080 Ti</td>
    <td>CentOS 7</td>
    <td>yes</td>
  </tr>
</table>

<h3 id="job-types-runtimes-and-per-user-limitations">Job types, runtimes, and per-user limitations</h3>

<p><strong>Jobs running in the CHTC GPU Lab have different time limits than normal CHTC job
submissions</strong>.</p>

<p>See the table below for the default runtime limits for normally submitted jobs</p>

<table class="gtable">
  <thead>
    <tr>
      <th>Job type</th>
      <th>Maximum runtime</th>
      <th>Per-user limitation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Short</td>
      <td>12 hrs</td>
      <td>2/3 of CTHC GPU Lab GPUs</td>
    </tr>
    <tr>
      <td>Medium</td>
      <td>24 hrs</td>
      <td>1/3 of CTHC GPU Lab GPUs</td>
    </tr>
    <tr>
      <td>Long</td>
      <td>7 days</td>
      <td>1 job with 1-2 GPUs</td>
    </tr>
    <tr>
      <td>Pre-emptable (backfill)</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>

<p>For interactive jobs, the default time limit is 4 hours and only 1 GPU can be requested 
at once.</p>

<p>These job types, runtimes, and per-user limitations are subject to change with
short notice as the CHTC GPU Lab studies usage patterns.</p>

<h2 id="b-researcher-owned-gpus">B. Researcher Owned GPUs</h2>

<p>Some GPU servers in CHTC have 
been purchased for specific research groups and are prioritized for
their group members. If you set the submit file option <code>+WantFlocking</code>
to true, your jobs are eligible to run on all GPU servers in CHTC, but
they are no longer guaranteed a 72-hour run time – see <a href="#d-access-shared-and-research-group-gpus-optional">below</a>.</p>

<h2 id="c-see-all-available-resources">C. See All Available Resources</h2>

<p>You can also find out information about GPUs in CHTC through the
<code>condor_status</code> command. All of our servers with GPUs have a <code>TotalGPUs</code>
attribute that is greater than zero; thus we can query the pool to find
GPU-enabled servers by running:</p>

<pre class="term"><code>[alice@submit]$ condor_status -compact -constraint 'TotalGpus &gt; 0'
</code></pre>

<p>To print out specific information about a GPU server and its GPUs, you
can use the “auto-format” option for <code>condor_status</code> and the names of
specific server attributes. For example, the tables above can be mostly
recreated using the attributes <code>Machine</code>, <code>TotalGpus</code> and
<code>CUDADeviceName</code>:</p>

<pre class="term"><code>[alice@submit]$ condor_status -compact -constraint 'TotalGpus &gt; 0' -af Machine TotalGpus CUDADeviceName
</code></pre>

<p>In addition, HTCondor tracks other GPU-related attributes for each
server, including:</p>

<table class="gtable">
	<tr>
		<th>Attribute </th>
		<th>Explanation </th>
	</tr>
	<tr>
		<td><code>Gpus</code></td>
		<td>Number of GPUs in an individual job slot on a server (one server can be divided into slots to run multiple jobs).</td>
	</tr>
	<tr>
		<td><code>TotalGPUs</code></td>
		<td>The total number of GPUs on a server.</td>
	</tr>
	<tr>
		<td><code>CUDADeviceName</code></td>
		<td>The type of GPU card.</td>
	</tr>
	<tr>
		<td><code>CUDACapability</code></td>
		<td>Represents various capabilities of the GPU. Can be used as a proxy for the GPU card type when 
		requiring a specific type of GPU. More details on what the capability numbers mean can be found on the 
		<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities">
		NVIDIA website</a>.</td>
	</tr>
	<tr>
		<td><code>CUDADriverVersion</code></td>
		<td>Maximum CUDA runtime version supported by the GPU drivers on the server. </td>
	</tr>
	<tr>
		<td><code>CUDAGlobalMemoryMb</code></td>
		<td>Amount of memory available on the GPU card.</td>
	</tr>
</table>

<h1 id="2-submit-jobs-using-gpus">2. Submit Jobs Using GPUs</h1>

<p>The following sections describe how to alter your HTCondor submit file in order 
to access the GPUs in CHTC.</p>

<h2 id="a-request-gpus-required">A. Request GPUs (required)</h2>

<p>All jobs that use GPUs must request GPUs in their submit file (along
with the usual requests for CPUs, memory and disk).</p>

<pre class="sub"><code>request_gpus = 1
</code></pre>

<p>It is important to still request at least one CPU per job to do the
processing that is not well-suited to the GPU.</p>

<p>Note that HTCondor will make sure your job has access to the GPU – you
shouldn’t need to set any environmental variables or other options
related to the GPU, except what is needed inside your code.</p>

<h2 id="b-use-the-gpu-lab-servers-recommended">B. Use the GPU Lab Servers (recommended)</h2>

<p>To accept the CHTC GPU Lab policies and opt-in to use these GPUs, add the
following line to your submit file:</p>

<pre class="sub"><code>+WantGPULab = true
</code></pre>

<p><strong>REMINDER</strong>: As described <a href="#job-types-runtimes-and-per-user-limitations">above</a>, using 
the GPU Lab servers means that default CHTC job limits 
are changed, including the length of the job. 
To specify the job type, indicate which category of job length you would like 
to use for your job, using the syntax described below:</p>

<table class="gtable">
  <thead>
    <tr>
      <th>Job type</th>
      <th>Maximum runtime</th>
      <th>Per-user limitation</th>
      <th>Submit file flag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Short</td>
      <td>12 hrs</td>
      <td>2/3 of CTHC GPU Lab GPUs</td>
      <td><code>+GPUJobLength = "short"</code></td>
    </tr>
    <tr>
      <td>Medium</td>
      <td>24 hrs</td>
      <td>1/3 of CTHC GPU Lab GPUs</td>
      <td><code>+GPUJobLength = "medium"</code></td>
    </tr>
    <tr>
      <td>Long</td>
      <td>7 days</td>
      <td>1 job with 1-2 GPUs</td>
      <td><code>+GPUJobLength = "long"</code></td>
    </tr>
  </tbody>
</table>

<p>If you do not specify a job type, the <code>medium</code> job type will be used as the default.</p>

<h2 id="c-request-specific-gpus-or-cuda-functionality-optional">C. Request Specific GPUs or CUDA Functionality (optional)</h2>

<p>If your software or code requires a specific version of CUDA, a certain
type of GPU, or has some other special requirement, you will need to add
a “requirements” statement to your submit file that uses one of the
attributes shown above.</p>

<p>If you want a certain class of GPU, use CUDACapability:</p>

<pre class="sub"><code>requirements = (CUDACapability == 7.5)
</code></pre>

<p>This table shows the “CUDACapability” value for our general use GPUs:</p>

<table class="gtable">
  <tr>
    <th>GPU Model</th>
    <th>CUDACapability</th>
  </tr>
  <tr>
   <td>Tesla P100-PCIE-16GB</td>
   <td>6.0</td>
  </tr>
  <tr>
    <td>GeForce RTX 2080 Ti </td>
    <td>7.5</td>
  </tr>
</table>

<blockquote>
  <p>It may be tempting to add requirements for specific GPU servers or
types of GPU cards. However, when possible, it is best to write your
code so that it can run across GPU types and without needing the
latest version of CUDA.</p>
</blockquote>

<h2 id="d-access-research-group-gpus-optional">D. Access Research Group GPUs (optional)</h2>

<p>As alluded to above, certain GPU servers in CHTC are prioritized for the
research groups that own them, but are available to run other jobs when
not being used by their owners. When running on these servers, jobs
forfeit our otherwise guaranteed runtime of 72 hours; however, for
shorter jobs, this is not a drawback and allowing jobs to run on these
additional servers opens up more capacity. To allow jobs to run on these
research-group owned servers if there is space, add the “Flocking”
option to your submit file:</p>

<pre class="sub"><code>+wantFlocking = true
</code></pre>

<h2 id="e-use-the-gzk-servers-optional">E. Use the <code>gzk</code> Servers (optional)</h2>

<p>The default operating system for jobs in CHTC is now CentOS 7. <strong>If you
want to use the <code>gzk-*</code> GPU nodes shown above, you’ll need to
specifically request the use of Scientific Linux 6 as an operating
system.</strong> There is an example of how to do this in our <a href="/os-transition.shtml">Operating System
guide</a>.</p>

<h1 id="3-preparing-software-using-gpus">3. Preparing Software Using GPUs</h1>

<p>Before using GPUs in CHTC you should ensure that the use of GPUs will
actually help your program run faster. This means that the code or
software you are using has the special programming required to use GPUs
and that your particular task will use this capability.</p>

<p>If this is the case, there are several ways to run GPU-enabled software
in CHTC:</p>

<blockquote>
  <p><strong>Machine Learning</strong><br />
 For those using machine learning code specifically, we have a guide
with more specific recommendations here: <a href="/machine-learning-htc.shtml">Run Machine Learning Jobs on
HTC</a></p>
</blockquote>

<h2 id="a-compiled-code">A. Compiled Code</h2>

<p>You can use our conventional methods of creating a portable installation
of a software package (as in our R/Python guides) to run on GPUs. Most
of our build servers or GPU servers have copies of the CUDA Runtime that
can be used to compile code. To access these servers, submit an
interactive job, following the instructions in our <a href="/inter-submit">Build Job
Guide</a> or by submitting a GPU job submit file with the
interactive flag for <code>condor_submit</code>. Once on a build or GPU server, see
what CUDA versions are available by looking at the path
<code>/user/local/cuda-*</code>.</p>

<p>Note that we strongly recommend software installation strategies that
incorporate the CUDA runtime into the final installed code, so that jobs
are able to run on servers even if a different version of the CUDA
runtime is installed (or there’s no runtime at all!). For compiled code,
look for flags that enable static linking or use one of the solutions
listed below.</p>

<h2 id="b-docker">B. Docker</h2>

<p>CHTC’s GPU servers have “nvidia-docker” installed, a specific version of
Docker that integrates Docker containers with GPUs. If you can find or
create a Docker image with your software that is based on the
nvidia-docker container, you can use this to run your jobs in CHTC. See
our <a href="/docker-jobs.shtml">Docker guide</a> for how to use Docker in CHTC.</p>

<h1 id="4-using-gpus-on-the-open-science-grid">4. Using GPUs on the Open Science Grid</h1>

<p>CHTC, as a member of the Open Science Grid (OSG) can access GPUs that
are available on the OSG. See <a href="/scaling-htc.shtml">this guide</a> to know
whether your jobs are good candidates for the OSG and then get in touch
with CHTC’s Research Computing Facilitators to discuss details.</p>




<div id = "copyright">
     <p align = "center"> 
	  
     For all user support, questions, and comments:
     <strong><a href="mailto:chtc@cs.wisc.edu">chtc@cs.wisc.edu</a></strong>

</p>
</div>

</div>

  </td>
  </tr>

</TABLE>
</td>
</table>

</body>
</html>


