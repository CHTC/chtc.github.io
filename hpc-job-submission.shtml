
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">

<html>
<head>
<script type="text/javascript">

  function resizeIframe(iframe) {
    var newheight;
    var newwidth;

    if(document.getElementById){
        newwidth=iframe.contentWindow.document.body.scrollWidth;
        newheight=iframe.contentWindow.document.body.scrollHeight;
    }

    iframe.height= (newheight) + "px";
    iframe.width= (newwidth) + "px";
  }
</script>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Submitting and Managing Jobs Using SLURM</title>

<link href="/web.css" rel="stylesheet" type="text/css">
</head>
<body leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">

<table width="100%" border="0" cellspacing="0" cellpadding="0">
<tr>
   <td width="1%" align="left" class="bgred" valign="top">
      <div align="center">
      &nbsp;<br>
      <a href="http://www.wisc.edu">

      <img src="/images/uw-sm-red.png" width="125" height="46" border="0"> </a>
       </div>

	<ul class="sidebar">
	<li><a href="/">CHTC Home</a></li>
	
	<li>About
		<ul>
		<li><a href="/approach.shtml">Our Approach</a></li>
<!--comment		<li><a href="/resources.shtml">Our Resources</a></li>   -->
		<li><a href="/projects.shtml">Our Customers</a></li>
		<li><a href="/people.shtml">Our Staff</a></li>
		<li><a href="/jobs.shtml">Our Open Positions</a></li>
		</ul>
	</li>
	
	<li>How To's
		<ul>
		<li><a href="/get-started.shtml">Get Started</a></li>
		<li><a href="/get-help.shtml">Get Help</a></li>
        	<li><a href="/guides.shtml">All User Guides</a></li>
                <li><a href="/use-submit-node.shtml">Use an HTC Submit Server</a></li>
		<li><a href="/helloworld.shtml">Run Your First HTC Jobs</a></li>
		<li><a href="/howto_overview.shtml">HTC for MatLab, Python or R</a></li>
		<li><a href="/HPCuseguide.shtml">Use the HPC Cluster</a></li>
		<li><a href="/cite-chtc.shtml">Cite CHTC Resources</a></li>
		</ul>
	</li>
	<li><a href="/user-news.shtml">User News</a></li>
	<li>Other Resources
		<ul>
		<!--<li><a href="http://monitor.chtc.wisc.edu/uw_condor_usage/usage1.shtml">Pool Usage Reports</a></li>-->
<!--comment		<li><a href="/opmetrics.shtml">Operational Metrics</a></li>  -->
		<li><a href="/gpu-lab.shtml">CHTC GPU Lab</a></li>
		<li><a href="http://research.cs.wisc.edu/htcondor/">HTCondor Project</a></li>
		<li><a href="http://www.neos-server.org/">NEOS Optimization Service</a></li>
		<li><a href="http://www.opensciencegrid.org/">Open Science Grid</a></li>
		<li><a href="http://wid.wisc.edu/">WID (Wisconsin Institute for Discovery)</a></li>
		</ul>
	</li>
	</ul>

	</td>

<td width="97%" valign="top"> 


	<TABLE SUMMARY="Navigation layout" BORDER="0" WIDTH="100%" CELLSPACING="0" CELLPADDING="0">
<TR ALIGN="left"> 
  <TD WIDTH="100%" height="400" Align="left" VALIGN="top"> 
    <A  name="body"></a> 
	<div id = "main">

<!-- Top of Page Body -->
<table BORDER="0" WIDTH="100%">
<!-- <h1 align=left valign=center>The Center for High Throughput Computing</h1> -->

<div id="osg_power"> <span style="height: 30px">Powered by:</span><br /><a href="http://opensciencegrid.org"><img alt="Open Science Grid" src="/images/Open_Science_Grid_Consortium(Logo).jpg" width="123" height="70" /></a></div>

<div id="hours"> <span style="height: 30px">
	<a href="https://twitter.com/CHTC_UW" style="color:white;"><center><img alt="Twitter" src="/images/twitter.png" width="50" height="50"></center></a> 
	<center><a href="https://github.com/CHTC/chtc-website-source" style="color:white;"><img alt="GitHub" src="/images/GitHub_Logo_White.png" width="92" height="38"></center></a></span></div>

<div id="hours"> <span style="height: 35px">
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<a href="http://chtc.cs.wisc.edu/get-help.shtml" style="color:white;">
<center><b>Office Hours!</b>
<p style="margin-bottom: 1px;"></p>
Tues/Thurs, 3-5pm
Click for details
</center></a></span>
<p style="margin-bottom: 1px;"></p>
<center><a href="http://chtc.cs.wisc.edu/sign-in.shtml" style="color:white;">Sign-In Here</a></center>
</div>
	
<div style="margin-top:1em;"><a href="http://chtc.cs.wisc.edu/"><img alt="Center for High Throughput Computing" src="/images/CHTC-logo.png" width="500" height="90"></a></div>


<link rel="stylesheet" type="text/css" href="/bootstrap.css" />

<h1>Disclaimer:</h1>
<p style="background-color:yellow;">This guide pertains to the new configuration of the HPC 
cluster which will be available starting <b>October 15</b>. For instructions on the currently 
operating cluster, please see our previous <a href="HPCuseguide.shtml">HPC Basic Use Guide</a></p>
<hr>
<h1>Additional HPC Guides</h1>
<br>
<div class="card-deck">
	<div class="card border-secondary h-100 text-center">  
		<a href="connecting.shtml"><li class="list-group-item list-group-item-action list-group-item-dark h-100" style="width: auto; height: auto !important;">Connecting to CHTC</li></a>
	</div>
	<div class="card border-secondary h-100 text-center">  
		<a href="hpc-overview.shtml"><li class="list-group-item list-group-item-action list-group-item-dark h-100" style="width: auto; height: auto !important;">HPC Overview</li></a>
	</div>
	<div class="card border-secondary h-100 text-center">  
		<a href="hpc-job-submission.shtml"><li class="list-group-item list-group-item-action list-group-item-dark h-100" style="width: auto; height: auto !important;">HPC Job Submission</li></a>
	</div>
	<div class="card border-secondary h-100 text-center">  
		<a href="hpc-software.shtml"><li class="list-group-item list-group-item-action list-group-item-dark h-100" style="width: auto; height: auto !important;">HPC Software</li></a>
	</div>
</div>
<hr>
<h1>Submitting and Managing Jobs Using SLURM</h1>


<p>The HPC Cluster uses SLURM to manage jobs on the HPC Cluster. This page describes 
how to submit and manage jobs using SLURM.</p>

<h1 id="contents">Contents</h1>

<ol>
  <li><a href="#1-submitting-jobs-using-slurm">Submitting Jobs Using SLURM</a></li>
  <li><a href="#2-viewing-jobs-in-the-queue">Viewing Jobs in the Queue</a></li>
  <li><a href="#3-viewing-additional-job-information">Viewing Additional Job Information</a></li>
  <li><a href="#4-removing-or-holding-jobs">Removing or Holding Jobs</a></li>
</ol>

<p>The following assumes that you have been granted access to the HPC cluster 
and can log into the head node <code>aci-login-1.chtc.wisc.edu</code>. If this is not
the case, please see the <a href="/form">CHTC account application page</a> or email
the facilitation team at chtc@cs.wisc.edu.</p>

<h1 id="1-submitting-jobs-using-slurm"><strong>1. Submitting Jobs Using SLURM</strong></h1>

<h2 id="a-submitting-a-job"><strong>A. Submitting a Job</strong></h2>

<p>Jobs can be submitted to the cluster using a submit file, sometimes also 
called a “batch” file. The top half of the file consists of <code>#SBATCH</code> 
options which communicate needs or parameters of the job – these lines 
are <strong>not</strong> comments, but essential options for the job. The values for 
<code>#SBATCH</code> options should reflect the size of nodes and run time limits 
described <a href="/hpc-overview">here</a>.</p>

<p>After the <code>#SBATCH</code> options, the submit file should contain the commands
needed to run your job, including loading any needed software modules.</p>

<p>An example submit file is given below. It requests 2 nodes of 16 cores 
and 64GB of memory each (so 32 cores and 128 GB of memory total), on the 
<code>univ</code> partition. It also specifies a run time limit of 4.5 hours.</p>

<pre><code class="language-{.sub}">#!/bin/sh
#This file is called submit-script.sh
#SBATCH --partition=univ        # default "univ", if not specified
#SBATCH --time=0-04:30:00       # run time in days-hh:mm:ss
#SBATCH --nodes=2               # require 2 nodes
#SBATCH --ntasks-per-node=16    # cpus per node (by default, "ntasks"="cpus")
#SBATCH --mem=64000             # RAM per node
#SBATCH --error=job.%J.err
#SBATCH --output=job.%J.out
# Make sure to change the above two lines to reflect your appropriate
# file locations for standard error and output

# Now list your executable command (or a string of them).
# Example for code compiled with a software module:
module load mpimodule
mpirun -n 32 /software/username/mpiprogram
</code></pre>

<p>Once the submit file is created, it can be submitted using the <code>sbatch</code> command:</p>

<pre class="term"><code>[alice@login]$ sbatch submit-script.sh
</code></pre>

<h2 id="b-optimizing-your-submit-file"><strong>B. Optimizing Your Submit File</strong></h2>

<p>There are other <code>SBATCH</code> options that can be used in the SLURM submit file. 
Other lines that you may wish to add to your script for specifying a
number of total tasks (equivalent to "cores" by default), desired CPU
cores per task (for multiple CPU cores per MPI task), or RAM per
cpu are:</p>

<pre><code class="language-{.sub}">#SBATCH --mem-per-cpu=4000         # RAM per cpu, in MB
#SBATCH --ntasks=32        # total number of "tasks" (cores) requested
#SBATCH --cpus-per-task=1  # default "1" if not specified
</code></pre>

<p>No matter which options you choose, it is important to make sure that your request fits within
the hardware configuration of your chosen partition.</p>

<p>If using the <code>pre</code> partition, we recommend making your resource requests in a way that 
will allow jobs to run on both the <code>univ</code> and <code>univ2</code> servers, specifically:</p>

<pre><code class="language-{.sub}">#!/bin/sh
#SBATCH --partition=pre        # default "univ", if not specified
#SBATCH --time=0-04:30:00       # run time in days-hh:mm:ss
#SBATCH --nodes=2               # require 2 nodes
#SBATCH --ntasks-per-node=16    # cpus per node (by default, "ntasks"="cpus")
#SBATCH --mem=64000             # RAM per node
</code></pre>

<h2 id="c-requesting-an-interactive-job-int-and-pre-partitions"><strong>C. Requesting an Interactive Job ("int" and "pre" partitions)</strong></h2>

<p>If you want to run your job commands yourself, as a test before submitting 
a job as described above, you can request an interactive job on the cluster. 
There is a dedicated partition 
for interactive work called <code>int</code>; you may request up to a full node (16 CPUs, 
64 GB RAM) when requesting an interactive session in the "int" partition and 
the session is limited to 30 minutes. Using another partition (like <code>pre</code>) will 
mean your interactive job is subject to the limits of that partition.</p>

<p>The command to request an interactive job is <code>srun</code>, and includes the partition
in which you’d like to run the interactive job.</p>

<pre class="term"><code>[alice@login]$ srun -n16 -N1 -p int --pty bash
</code></pre>

<p>The above example indicates a request for 16 CPUs (<code>-n16</code>) on a single
node (<code>-N1</code>) in the "int" partition (<code>-p int</code>), and "<code>-t 15</code>" would
indicate a request for 15 minutes, if desired rather than the 30-minute
default. After the interactive shell is created to a compute node with
the above command, you'll have access to files on the shared file
system and be able to execute code interactively as if you had directly
logged in to that node. <strong>It is important to exit the interactive shell
when you're done working by typing <code>exit</code></strong>.</p>

<h1 id="2-viewing-jobs-in-the-queue"><strong>2. Viewing Jobs in the Queue</strong></h1>

<p>To view your jobs in the SLURM queue, use the following command:</p>

<pre class="term"><code>[alice@login]$ squeue -u username
</code></pre>

<p>Issuing <code>squeue</code> alone will show all user jobs in the queue. You can
view all jobs for a particular partition with <code>squeue -p univ</code>.</p>

<h1 id="3-viewing-additional-job-information"><strong>3. Viewing Additional Job Information</strong></h1>

<p>Accounting information for jobs that are invoked with SLURM are logged. The <code>sacct</code>	 command displays job accouting data in a variety of forms for your analysis.</p>

<p><strong>If you are having trouble viewing output from <code>sacct</code> try running this command first</strong></p>

<pre class="term"><code>[alice@login]$ sacct --start=2018-01-01
</code></pre>

<h2 id="how-to-select-jobs">How To Select Jobs</h2>

<ul>
  <li>
    <p>To display information about a specific job or list of jobs use <code>-j</code> or <code>--jobs</code> followed by a job number or comma separated list of job numbers.</p>

    <pre class="term"><code>  [alice@login]$ sacct --jobs job1,job2,job3
</code></pre>
    <!-- Sample output -->
  </li>
  <li>
    <p>To select information about jobs in a certain date range use <code>--start</code> and <code>--end</code> Without it, <code>sacct</code> will only return jobs from the current day.</p>

    <pre class="term"><code>  [alice@login]$ sacct --start=YYYY-MM-DD
</code></pre>
  </li>
  <li>To select information about jobs in a certian time range use <code>--starttime</code> and <code>--endtime</code> The default start time is 00:00:00 of the current day, unless used with <code>-j</code>, then the default start time is Unix Epoch 0. The default end time is time of running the command. Valid time formats are
    <pre><code>  HH:MM[:SS] [AM|PM]
  MMDD[YY] or MM/DD[/YY] or MM.DD[.YY]
  MM/DD[/YY]-HH:MM[:SS]
  YYYY-MM-DD[THH:MM[:SS]] 
</code></pre>

    <pre class="term"><code>  [alice@login]$ sacct --starttime 08/23 --endtime 08/24
</code></pre>
  </li>
  <li>
    <p>To display another user’s jobs use <code>--user</code></p>

    <pre class="term"><code>  [alice@login]$ sacct --user BuckyBadger
</code></pre>
    <p><!-- Sample output --></p>
  </li>
  <li>
    <p>To only show statistics relevant to the job allocation itself, not taking steps into consideration use <code>-X</code>. This can be useful when trying to figure out which part of a job errored out.</p>

    <pre class="term"><code>  [alice@login]$ sacct -X
</code></pre>
    <p><!-- Sample Output --></p>
  </li>
</ul>

<h2 id="displaying-specific-fields">Displaying Specific Fields</h2>

<p><code>sacct</code> can display different fields about your jobs. You can use the <code>--helpformat</code> flag to get a full list.</p>

<pre class="term"><code>[alice@login]$ sacct --helpformat
</code></pre>

<h3 id="recommended-fields">Recommended Fields</h3>

<p>When looking for information about your jobs CHTC recommends using these fields</p>
<pre><code>elapsed
end
exitcode
jobid
ncpus
nnodes
nodelist
ntasks
partition
start
state
submit
user
</code></pre>

<p>For example run</p>

<pre class="term"><code>sacct --start=2020-01-01 --format=jobid
</code></pre>

<p>to see jobIDs of all jobs ran since 1/1/2020.</p>

<h1 id="4-removing-or-holding-jobs"><strong>4. Removing or Holding Jobs</strong></h1>

<p>You can kill and/or remove your job from the
queue with the following:</p>

<pre class="term"><code>[alice@login]$ scancel job#
</code></pre>

<p>where <code>job#</code> is the number shown for your job in the <code>squeue</code> output.</p>

<p>If you want to leave a job in the queue, but prevent it from running immediately, 
you can “hold” a submitted job by using:</p>

<pre class="term"><code>[alice@login]$ scontrol hold job#
</code></pre>

<p>To release jobs that are held so that they can run, use this command:</p>

<pre class="term"><code>[alice@login]$ scontrol release job#
</code></pre>



<div id = "copyright">
     <p align = "center"> 
	  
     For all user support, questions, and comments:
     <strong><a href="mailto:chtc@cs.wisc.edu">chtc@cs.wisc.edu</a></strong>

</p>
</div>

</div>

  </td>
  </tr>

</TABLE>
</td>
</table>

</body>
</html>


